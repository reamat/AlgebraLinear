%Este trabalho está licenciado sob a Licença Creative Commons Atribuição-CompartilhaIgual 3.0 Não Adaptada. Para ver uma cópia desta licença, visite https://creativecommons.org/licenses/by-sa/3.0/ ou envie uma carta para Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.

%\documentclass[../livro.tex]{subfiles}  %%DM%%Escolher document class and options article, etc

%define o diretório principal
\providecommand{\dir}{..}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%INICIO DO DOCUMENTO%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{document}

\chapter{Semanas 6 e 7}



\section{Espaços vetoriais}

Nós vimos que um espaço vetorial (sobre o conjunto $\mathbb{R}$ de escalares) é um conjunto $V$ equipado com as operações de soma de vetores e de multiplicação por escalar e que satisfazem as propriedades usuais dos espaços $\mathbb{R}^n$.



\section{Bases de espaços vetoriais}


Uma \textbf{base} para um espaço vetorial $V$ é um conjunto $\mathcal{B}$ que:
\begin{enumerate}[(a)]
	\item gera $V$ e;
	\item é linearmente independente.
\end{enumerate}


\begin{ex}
	$\mathbb{R}^n$ é um espaço vetorial sobre $\mathbb{R}$. Vimos anteriormente que os vetores
	\begin{equation}
	\vec{e}_1 =
	\left[
	\begin{array}{c}
	1 \\
	0 \\
	\vdots \\
	0
	\end{array}
	\right], \vec{e}_2 =
	\left[
	\begin{array}{c}
	0 \\
	1 \\
	\vdots \\
	0
	\end{array}
	\right], \cdots, \vec{e}_n =
	\left[
	\begin{array}{c}
	0 \\
	0 \\
	\vdots \\
	1
	\end{array}
	\right]
	\end{equation} formam um conjunto linearmente independente. E também é verdade que eles geram $\mathbb{R}^n$, pois qualquer vetor pode ser escrito como combinação linear deles:
	\begin{equation}
	\vec{v} =
	\left[
	\begin{array}{c}
	x_1 \\
	x_2 \\
	\vdots \\
	x_n
	\end{array}
	\right] = x_1
	\left[
	\begin{array}{c}
	1 \\
	0 \\
	\vdots \\
	0
	\end{array}
	\right] + x_2
	\left[
	\begin{array}{c}
	0 \\
	1 \\
	\vdots \\
	0
	\end{array}
	\right] + \cdots + x_n
	\left[
	\begin{array}{c}
	0 \\
	0 \\
	\vdots \\
	1
	\end{array}
	\right] = x_1 \vec{e}_1 + x_2 \vec{e}_2 + \cdots + x_n \vec{e}_n.
	\end{equation} Portanto, o conjunto de $n$ elementos $\{\vec{e}_1, \vec{e}_2, \dots, \vec{e}_n\}$ é uma base de $\mathbb{R}^n$.
\end{ex}



Várias propriedades interessantes aparecem naturalmente como consequência da definição de base. Suponhamos que um conjunto $\mathcal{B} = \{\vec{v}_1, \vec{v}_2, \dots, \vec{v}_d\} \subset V$ seja uma base de um espaço vetorial $V$. Já que $\Span \mathcal{B} = V$, qualquer elemento de $V$ pode ser representado como
\begin{equation}
\vec{v} = x_1 \vec{v}_1 + x_2 \vec{v}_2 + \cdots + x_d \vec{v}_d.
\end{equation} Além disso, o fato de ser $\mathcal{B}$ um conjunto linearmente independente nos diz que esta forma de representar o vetor $\vec{v}$ é única! De fato, vamos verificar que qualquer representação é, na realidade, a mesma representação que tínhamos acima: se tivermos
\begin{equation}
\vec{v} = k_1 \vec{v}_1 + k_2 \vec{v}_2 + \cdots + k_d \vec{v}_d,
\end{equation} deveremos também ter
\begin{equation}
(x_1-k_1) \vec{v}_1 + (x_2-k_2) \vec{v}_2 + \cdots + (x_d-k_d) \vec{v}_d = \vec{v} - \vec{v} = \vec{0}.
\end{equation} Sendo a base $\mathcal{B}$ formada por vetores LI, concluímos que os coeficientes da combinação linear acima devem ser nulos, isto é, $x_1=k_1, x_2=k_2,\dots,x_d=k_d$. Portanto,
\begin{equation}
\boxed{
	\begin{array}{c}
\text{Todo vetor pode ser representado de maneira única como combinação linear} \\ \text{dos elementos de uma base.}
	\end{array}
}
\end{equation}
Uma segunda propriedade fundamental é a seguinte:
\begin{equation}
\boxed{
	\text{Toda base de um espaço vetorial fixado possui o mesmo número de elementos.}
}
\end{equation}


\begin{proof}[Justificativa] Sejam duas bases $\mathcal{B}_1 = \{\vec{v}_1, \vec{v}_2, \dots, \vec{v}_d\} \subset V$ e $\mathcal{B}_2 = \{\vec{w}_1, \vec{w}_2, \dots, \vec{w}_k\} \subset V$ do mesmo espaço vetorial $V$. Nós podemos escrever os elementos da base $\mathcal{B}_1$ como combinações lineares dos elementos da base $\mathcal{B}_2$:
	\begin{equation}
	\left\{
	\begin{array}{rcl}
	\vec{v}_1 &=& a_{11} \vec{w}_1 + a_{21} \vec{w}_2 + \cdots + a_{k1} \vec{w}_k \\
	\vec{v}_2 &=& a_{12} \vec{w}_1 + a_{22} \vec{w}_2 + \cdots + a_{k2} \vec{w}_k \\
	&     \vdots& \\
	\vec{v}_d &=& a_{1d} \vec{w}_1 + a_{2d} \vec{w}_2 + \cdots + a_{kd} \vec{w}_k
	\end{array}
	\right.
	\end{equation} O problema é que, se tivéssemos quantidades diferentes de vetores nas bases, digamos $k<d$, então a equação
	\begin{equation}\label{1111}
	b_1 \vec{v}_1 + b_2 \vec{v}_2 + \cdots + b_d \vec{v}_d = \vec{0}
	\end{equation} possuiria soluções não triviais, contradizendo o fato de ser $\mathcal{B}_1$ um conjunto linearmente independente. De fato, utilizando que $\mathcal{B}_1$ é linearmente independente, encontrar $b_1, b_2, \dots, b_k$ na equação \eqref{1111} fica equivalente a resolver
	\begin{equation}
	\left[
	\begin{array}{cccc}
	a_{11} & a_{12} & \cdots & a_{1d} \\
	a_{21} & a_{22} & \cdots & a_{2d} \\
	\vdots & \vdots &        & \vdots \\
	a_{k1} & a_{k2} & \cdots & a_{kd}
	\end{array}
	\right]
	\left[
	\begin{array}{c}
	b_1 \\
	b_2 \\
	\vdots  \\
	b_d
	\end{array}
	\right] =
	\left[
	\begin{array}{c}
	0 \\
	0 \\
	\vdots  \\
	0 \\
	\end{array}
	\right],
	\end{equation} que possui soluções não triviais quando $k<d$.

	Argumentando de forma parecida, concluímos também que não podemos ter $d<k$. Portanto, $d=k$.
\end{proof}


O número de elementos de uma base do espaço vetorial $V$ é chamado de \textbf{dimensão} de $V$. Graças à propriedade acima, tanto faz a base que considerarmos, pois todas tem o mesmo número de elementos. A dimensão de $V$, pelo que vimos até agora, indica o número de parâmetros necessários para representar qualquer vetor de $V$.

Quando um vetor $\vec{v}$ é escrito em termos dos elementos de uma base $\mathcal{B} = \{\vec{v}_1, \vec{v}_2, \dots, \vec{v}_d\}$, é comum utilizarmos a notação
\begin{equation}
\vec{v} = x_1 \vec{v}_1 + x_2 \vec{v}_2 + \cdots  + x_d \vec{v}_d =
\left[
\begin{array}{c}
x_1 \\
x_2 \\
\vdots \\
x_{d-1} \\
x_d
\end{array}
\right]_{\mathcal{B}} \text{ ou ainda } \big[ \vec{v} \big]_{\mathcal{B}} =
\left[
\begin{array}{c}
x_1 \\
x_2 \\
\vdots \\
x_{d-1} \\
x_d
\end{array}
\right].
\end{equation}

\begin{ex}
	O conjunto
	\begin{equation}
	\mathcal{P}_3 (\mathbb{R}) = \big\{ p(x) = a_3 x^3 + a_2 x^2 + a_1 x + a_0 \text{ tais que } a_0, a_1, a_2, a_3 \in \mathbb{R} \big\}
	\end{equation} de todos os polinômios de grau 3 é um espaço vetorial. Uma base para este espaço pode ser encontrada ``de olho'': é fácil ver que o conjunto de polinômios
	\begin{equation}
	\big\{ x^3, x^2, x, 1 \big\}
	\end{equation} gera o espaço $\mathcal{P}_3 (\mathbb{R})$. Para ver que são LI, precisamos verificar que se tivermos
	\begin{equation}
	a_3 x^3 + a_2 x^2 + a_1 x + a_0 = 0, \quad \text{para todo } x \in \mathbb{R},
	\end{equation} então todos os coeficientes devem ser nulos. Isto segue do Teorema Fundamental da Álgebra\footnote{Mais geralmente, o Teorema Fundamental da Álgebra afirma que todo polinômio não nulo de grau $n$ possui exatamente $n$ raízes complexas; logo, no máximo $n$ raízes reais.}, que diz que todo polinômio não nulo de grau $3$ possui exatamente $3$ raízes complexas; logo, no máximo $3$ raízes reais. Portanto, já que no nosso caso, todos os valores de $x$ reais são raízes, nosso polinômio deve ser o constante igual a zero, de modo que todos os coeficientes são zero.

	Concluímos desta maneira que $\mathcal{B} = \big\{ x^3, x^2, x, 1 \big\}$ é uma base de $\mathcal{P}_3 (\mathbb{R})$, que consequentemente tem dimensão $4.$

	Desta maneira, qualquer elemento de $\mathcal{P}_3 (\mathbb{R})$ pode ser representado por $4$ parâmetros. Por exemplo,
	\begin{equation}
	p(x) = x^3 - 2 x^2 + 3 \ \rightsquigarrow \ [p(x)]_{\mathcal{B}} = \left[
	\begin{array}{c}
	1 \\
	-2 \\
	0 \\
	3
	\end{array}
	\right],
	\end{equation}
	\begin{equation}
	q(x) = 2 x^3 + x^2 + x -1 \ \rightsquigarrow \ [q(x)]_{\mathcal{B}} = \left[
	\begin{array}{c}
	2 \\
	1 \\
	1 \\
	-1
	\end{array}
	\right].
	\end{equation} Nota que a ordem que escrevemos os elementos de uma base altera as representações $[p]_{\mathcal{B}}$ e $[q]_{\mathcal{B}}$.
\end{ex}


\begin{ex}
	Em um curso de equações diferenciais, se aprende que o conjunto de todas as soluções de uma equação linear de segunda ordem da forma
	\begin{equation}
	y''(t) + f(x) y'(x) + g(x) y(x) = 0
	\end{equation} é uma espaço vetorial cuja dimensão é 2. Desta forma, por exemplo, sabendo que $y_1(x) = e^{2x}$ e $y_2 (x) = e^{-x}$ satisfazem a equação
	\begin{equation}\label{eqn:edo}
	y''(t) - y'(x) -2 y(x) = 0,
	\end{equation} podemos concluir que todas as soluções desta EDO podem ser escritas como combinação linear destas duas:
	\begin{equation}
	y(x) \text{ é solução de \eqref{eqn:edo} } \iff y(x) = C_1 e^{2x} + C_2 e^{-x}, \ \text{ para algumas constantes } C_1, C_2 \in \mathbb{R}.
	\end{equation}
\end{ex}


\subsection{Espaço nulo}

Vimos que o espaço nulo (núcleo) de uma matriz $A$ de ordem $m \times n$ é o conjunto definido por
\begin{equation}
\operatorname{Nul} A = \big\{ \vec{x} \in \mathbb{R}^n \, | \, A\vec{x} = \vec{0}  \big\}.
\end{equation} Nas notas da semana passada, vimos também o seguinte exemplo:

\begin{ex}
	Encontrar uma base para o espaço nulo da matriz
	\begin{equation}
	A = \left[
	\begin{array}{ccccc}
	1  & 0  & 3   & 1 & 2 \\
	-1 & 2  & -2  & 0 & 2 \\
	6  & -4 & 1   & 1 & -4
	\end{array}
	\right].
	\end{equation}
	Por escalonamento:
	\begin{equation}
	A \sim \left[
	\begin{array}{ccccc}
	1  & 0  & 3   & 1 & 2  \\
	0  & 2  & 1   & 1 & 4  \\
	0  & 4  & 17  & 5 & 16
	\end{array}
	\right] \sim \cdots \sim \left[
	\begin{array}{ccccc}
	1  & 0  & 0  & 2/5 & 2/5  \\
	0  & 1  & 0  & 2/5 & 26/15  \\
	0  & 0  & 1  & 1/5 & 8/15
	\end{array}
	\right] \sim
	\left\{
	\begin{array}{ll}
	x_1 = - \frac{2}{5} x_4 - \frac{2}{5} x_5  \\
	\\
	x_2 = - \frac{2}{5} x_4 - \frac{26}{15} x_5  \\
	\\
	x_3 = - \frac{1}{5} x_4 - \frac{8}{15} x_5
	\end{array}
	\right.
	\end{equation} Logo,
	\begin{equation}
	\left[
	\begin{array}{c}
	x_1 \\
	x_2 \\
	x_3 \\
	x_4 \\
	x_5
	\end{array}
	\right] =
	x_4 \left[
	\begin{array}{c}
	-2/5 \\
	-2/5 \\
	-1/5 \\
	1 \\
	0
	\end{array}
	\right] + x_5
	\left[
	\begin{array}{c}
	-2/5 \\
	-26/15 \\
	-8/15 \\
	0 \\
	1
	\end{array}
	\right]
	\end{equation} de modo que $\operatorname{dim} \operatorname{Nul} A = 2$ e uma base é
	\begin{equation}
	\left\{
	\left[
	\begin{array}{c}
	-2/5 \\
	-2/5 \\
	-1/5 \\
	1 \\
	0
	\end{array}
	\right],
	\left[
	\begin{array}{c}
	-2/5 \\
	-26/15 \\
	-8/15 \\
	0 \\
	1
	\end{array}
	\right]
	\right\}.
	\end{equation} Já que estes vetores são LI, temos uma base para $\operatorname{Nul} A. \ \lhd$
\end{ex}

É sempre possível obter uma base para $\operatorname{Nul} A$ desta forma. Enfatizamos esta propriedade abaixo:

\begin{equation}
\boxed{
\begin{array}{c}
\text{Uma base para $\operatorname{Nul} A$ pode ser encontrada por escalonamento ao resolver o sistema} \\
\text{homogêneo associado à matriz $A$. Além disso, a dimensão do espaço nulo é igual ao} \\
\text{número de variáveis livres do sistema.}
\end{array}
}
\end{equation}

\subsection{Espaço coluna}

Vimos também o espaço coluna de uma matriz $A$ de ordem $m \times n$, que é o espaço gerado pelas colunas de $A$:
\begin{equation}
A =
\left[
\begin{array}{cccc}
| & | &  & | \\
\vec{a}_1 & \vec{a}_2 & \cdots & \vec{a}_n \\
| & | &        & | \\
\end{array}
\right] \rightsquigarrow
\operatorname{Col} A = \Span \{ \vec{a}_1, \vec{a}_2, \dots, \vec{a}_n\}.
\end{equation} Desta forma, a definição de $\operatorname{Col} A$ já deixa claro um conjunto gerador: as colunas de $A$! Para determinar uma base, nós devemos ``excluir'' as colunas que podem ser geradas pelas demais, de modo a obter um conjunto linearmente independente.
\begin{equation}
\boxed{
	\begin{array}{c}
	\text{Uma base para $\operatorname{Col} A$ é formada pelas colunas pivô da matriz $A$. Para descobrir} \\
	\text{quais são as colunas pivô, procedemos por escalonamento. As \textit{colunas da matriz} } \\
	\text{\textit{original} formam uma base de $\operatorname{Col} A$. A dimensão do espaço coluna é } \\
	\text{igual ao número de colunas pivô da matriz.}
	\end{array}
}
\end{equation}


\begin{ex}
	Encontrar uma base para o espaço coluna da matriz
	\begin{equation}
	A = \left[
	\begin{array}{ccccc}
	1  & 0  & 3   & 1 & 2 \\
	-1 & 2  & -2  & 0 & 2 \\
	6  & -4 & 1   & 1 & -4
	\end{array}
	\right].
	\end{equation} Vimos acima que a forma escalonada reduzida de $A$ é
	\begin{equation}
	A \sim
	\left[
	\begin{array}{ccccc}
	1  & 0  & 0  & 2/5 & 2/5  \\
	0  & 1  & 0  & 2/5 & 26/15  \\
	0  & 0  & 1  & 1/5 & 8/15
	\end{array}
	\right],
	\end{equation} de modo que todas as colunas pivô são as três primeiras. Portanto, uma base de $\operatorname{Col} A$ é
	\begin{equation}
	\left\{
	\left[
	\begin{array}{c}
	1    \\
	-1  \\
	6
	\end{array}
	\right],
	\left[
	\begin{array}{c}
	0   \\
	2   \\
	-4
	\end{array}
	\right],
	\left[
	\begin{array}{c}
	3  \\
	-2 \\
	1
	\end{array}
	\right]
	\right\}.
	\end{equation}
\end{ex}




\begin{ex}
	Encontrar uma base para o espaço coluna da matriz
	\begin{equation}
	A = \left[
	\begin{array}{ccccccc}
		2  & 8  & 1  & 8 & 2 & 2 & 7  \\
	1  & 4  & 1  & 6 & 0 & 1 & 4  \\
	3  & 12 & 2  & 14 & 2 & 5 & 13  \\
	1  & 4  & 0  & 2 & 2 & 0 & 2
	\end{array}
	\right].
	\end{equation} Pode-se mostrar que a forma escalonada reduzida de $A$ é
	\begin{equation}
	A \sim
	\left[
	\begin{array}{ccccccc}
	1  & 4  & 0  & 2 & 2 & 0 & 2  \\
	0  & 0  & 1  & 4 & -2& 0 & 1  \\
	0  & 0  & 0  & 0 & 0 & 1 & 1  \\
	0  & 0  & 0  & 0 & 0 & 0 & 0
	\end{array}
	\right],
	\end{equation} de modo que as colunas pivô são a primeira, a terceira e a sexta. Portanto, uma base de $\operatorname{Col} A$ é
	\begin{equation}
	\left\{
	\left[
	\begin{array}{c}
	2    \\
	1  \\
	3    \\
	1
	\end{array}
	\right],
	\left[
	\begin{array}{c}
	1   \\
	1   \\
	2   \\
	0
	\end{array}
	\right],
	\left[
	\begin{array}{c}
	2  \\
	1 \\
	5  \\
	0
	\end{array}
	\right]
	\right\}.
	\end{equation}
\end{ex}

\subsection*{Exercícios resolvidos}

\construirExeresol

\subsection*{Exercícios}

\construirExer




\section{Teorema do núcleo e da imagem}


Nas seções anteriores, vimos que
\begin{equation}
\operatorname{dim} \operatorname{Col} A  = \operatorname{dim} \text{ da imagem de } A  = \text{ número de colunas pivô e }
\end{equation}
\begin{equation}
\operatorname{dim} \operatorname{Nul} A = \text{ número de variáveis livres do sistema homogêneo associado}.
\end{equation} Ora, mas ou uma coluna é pivô, ou sua variável associada pode ser considerada uma variável livre, de modo que temos o

\begin{teo}[Teorema do núcleo e da imagem]
	Para qualquer matriz $A$ de ordem $m\times n$, temos
	\begin{equation}
	\boxed{\operatorname{dim} \operatorname{Col} A + \operatorname{dim} \operatorname{Nul} A = n = \text{ número de colunas de } A.}
	\end{equation}
\end{teo}

\begin{obs}
	A dimensão do espaço coluna de $A$ ou, o que é a mesma coisa, dimensão da imagem da transformação linear $\vec{x} \mapsto A\vec{x}$, é também conhecida na literatura como o \textbf{posto de} $A$. Assim, o Teorema do núcleo e da imagem, também conhecido como o \textbf{Teorema do Posto}, pode ser reenunciado como: Se $A$ é uma matriz $m\times n$, então
	\begin{equation}
	\operatorname{posto} A + \operatorname{dim} \operatorname{Nul} A = n.
	\end{equation}
\end{obs}

\begin{obs}
	O teorema afirma que há uma relação entre as dimensões dos espaços coluna e nulo. No entanto, não esqueça que estes são subespaços de universos diferentes! Temos
	\begin{equation}
	\operatorname{Nul} A \subseteq \mathbb{R}^n \text{ enquanto que } \operatorname{Col} A \subseteq \mathbb{R}^m.
	\end{equation}
\end{obs}

Apesar da conclusão do teorema parecer simples, é muito útil na análise de sistemas lineares, ou de transformações lineares.

\begin{ex}
	Todo sistema linear de ordem $5 \times 9$ deve possuir um espaço nulo de dimensão $4$ ou mais. De fato, como a matriz associada tem apenas cinco linhas, pode ter no máximo $5$ posições de pivô, de modo que
	\begin{equation}
	\operatorname{dim} \operatorname{Col} A \le 5.
	\end{equation} Portanto
	\begin{equation}
	\operatorname{dim} \operatorname{Nul} A = 9 - \operatorname{dim} \operatorname{Col} A \ge 9 - 5 = 4.
	\end{equation} Desta forma, se resolvermos um sistema homogêneo desta ordem e encontrarmos um conjunto solução de dimensão 3, certamente  há algum um erro nas contas, pois o Teorema do núcleo e da imagem nos diz que há pelo menos 4 variáveis livres no conjunto solução deste sistema homogêneo. 
\end{ex}

\begin{ex}
 O Teorema do núcleo e da imagem garante que não pode existir uma transformação linear $T(x)=Ax$ sobrejetora de $ \mathbb{R}^3$ em  $ \mathbb{R}^4$, visto que 
 \begin{equation}
 \operatorname{posto} A + \operatorname{dim} \operatorname{Nul} A = 3
 \end{equation}
 e portanto $\operatorname{posto} A  \leq 3$. Ao lembrarmos que  $\operatorname{posto} A$ é o mesmo que a dimensão da imagem de $T$, concluímos que a imagem de $T$ não coincide com o contradomínio $ \mathbb{R}^4 $.
\end{ex}
 Também podemos usar o Teorema do núcleo e da imagem para provar que não existe uma transformação linear injetora de 
 $ \mathbb{R}^n$ em $ \mathbb{R}^m$ se $n>m$.













\subsection*{Exercícios resolvidos}

\construirExeresol

\subsection*{Exercícios}

\construirExer



\section{Matriz de mudança de coordenadas}

Se conhecemos as coordenadas do vetor $\vec{x}$ em uma base $\mathcal{B} = \big\{ \vec{v}_1, \vec{v}_2, \dots, \vec{v}_n \big\}$:
\begin{equation}
\big[ \vec{x} \big]_{\mathcal{B}} =
\left[
\begin{array}{c}
b_1 \\
b_2 \\
\vdots \\
b_n
\end{array}
\right]_{\mathcal{B}} = b_1 \vec{v}_1 + b_2 \vec{v}_2 + \cdots + b_n \vec{v}_n,
\end{equation} podemos obter as coordenadas usuais (na base canônica) de $\vec{x}$ de forma sistemática. Em outras palavras, queremos encontrar $x_1, x_2, \dots, x_n$ tais que
\begin{equation}
\vec{x} = \left[
\begin{array}{c}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{array}
\right] = x_1 \vec{e}_1 + x_2 \vec{e}_2 + \cdots + x_n \vec{e}_n.
\end{equation} Uma maneira é considerar a matriz cujas colunas são os vetores $\vec{v}_i$:
\begin{equation}
A =
\left[
\begin{array}{cccc}
| & | &  & | \\
\vec{v}_{1} & \vec{v}_{2} & \cdots & \vec{v}_{n} \\
| & | &  & |
\end{array}
\right] =
\left[
\begin{array}{cccc}
v_{11} & v_{12} & \cdots & v_{1n} \\
v_{21} & v_{22} & \cdots & v_{2n} \\
\vdots & \vdots &        & \vdots \\
v_{n1} & v_{n2} & \cdots & v_{nn}
\end{array}
\right].
\end{equation} Funciona porque
\begin{align*}
b_1 \vec{v}_1 + b_2 \vec{v}_2 + \cdots + b_n \vec{v}_n & = \sum_{j=1}^{n} b_j \vec{v}_j = \sum_{j=1}^{n} b_j \sum_{i=1}^{n} v_{ij} \vec{e}_i  = \sum_{i=1}^{n} \bigg(\sum_{j=1}^{n} b_j v_{ij}\bigg) \vec{e}_i \\
& = \bigg(\sum_{j=1}^{n} b_j v_{1j}\bigg) \vec{e}_1 + \bigg(\sum_{j=1}^{n} b_j v_{2j}\bigg) \vec{e}_2 + \cdots + \bigg(\sum_{j=1}^{n} b_j v_{nj}\bigg) \vec{e}_n.
\end{align*}
Assim, devemos ter
\begin{equation}
\left\{
\begin{array}{lcl}
x_1 &=& v_{11} b_{1} + v_{12} b_{2} + \cdots + v_{1n} b_{n} \\
x_2 &=& v_{21} b_{1} + v_{22} b_{2} + \cdots + v_{2n} b_{n} \\
&\vdots& \\
x_n &=& v_{n1} b_{1} + v_{n2} b_{2} + \cdots + v_{nn} b_{n}
\end{array}
\right. \quad \text{i.e} \quad \vec{x} = A [\vec{x}]_{\mathcal{B}}.
\end{equation}

A matriz $A$ construída como acima é chamada de \textbf{matriz de mudança de coordenadas} da base $\mathcal{B}$ para a base usual (canônica) $\{ \vec{e}_1, \vec{e}_2, \dots, \vec{e}_n\}$.

A matriz de mudança de coordenadas da base canônica para a base $\mathcal{B}$ pode ser obtida a partir da inversa de $A$:
\begin{equation}
[\vec{x}]_{\mathcal{B}} = A^{-1} \cdot \vec{x}.
\end{equation} (Notamos que a matriz $A$ é necessariamente invertível, já que suas colunas são elementos de uma base; em particular, são linearmente independentes).

\begin{ex}
	Consideramos a seguinte base para $\mathbb{R}^2$:
	\begin{equation}
	\mathcal{B} = \left\{
	\left[
	\begin{array}{c}
	1 \\
	1
	\end{array}
	\right],
	\left[
	\begin{array}{c}
	-1 \\
	1
	\end{array}
	\right]
	\right\}.
	\end{equation} Este conjunto é de fato uma base, pois são linearmente independentes e são dois (que é a dimensão de $\mathbb{R}^2$). Sabendo que as coordenadas de $\vec{u}$ e $\vec{v}$ nesta base $\mathcal{B}$ são
	\begin{equation}
	[u]_{\mathcal{B}} =
	\left[
	\begin{array}{c}
	1 \\
	1
	\end{array}
	\right]_{\mathcal{B}} \quad \text{e} \quad
	[v]_{\mathcal{B}} =
	\left[
	\begin{array}{c}
	3 \\
	-1
	\end{array}
	\right]_{\mathcal{B}},
	\end{equation} encontrar as componentes de $\vec{u}$ e $\vec{v}$ na base canônica $\{ \vec{e}_1, \vec{e}_2\}$ de $\mathbb{R}^2$.

	Pelo que analisamos acima, a matriz de mudança de coordenadas que procuramos é a matriz
	\begin{equation}
	A =
	\left[
	\begin{array}{cc}
	1 & -1 \\
	1 &  1
	\end{array}
	\right]
	\end{equation} Logo,
	\begin{equation}
	\left[
	\begin{array}{cc}
	1 & -1 \\
	1 &  1
	\end{array}
	\right] \left[
	\begin{array}{c}
	1 \\
	1
	\end{array}
	\right]_{\mathcal{B}} =
	\left[
	\begin{array}{c}
	0 \\
	2
	\end{array}
	\right] \text{ e } \vec{v} =
	\left[
	\begin{array}{cc}
	1 & -1 \\
	1 &  1
	\end{array}
	\right] \left[
	\begin{array}{c}
	3 \\
	-1
	\end{array}
	\right]_{\mathcal{B}} =
	\left[
	\begin{array}{c}
	4 \\
	2
	\end{array}
	\right].
	\end{equation}
\end{ex}


\begin{obs}
	A matriz de mudança de coordenadas é uma forma de trocar de uma base para outra de forma sistemática. Com o intuito de tornar mais intuitiva a construção, vamos repetir a argumentação que fizemos no início desta seção para o caso $2\times 2$. Na base $\mathcal{B}$ do exemplo anterior, a representação
	\begin{equation}
	\left[
	\begin{array}{c}
	b_1 \\
	b_2
	\end{array}
	\right]_{\mathcal{B}} \text{ significa que } \vec{v} = b_1 \cdot \left[
	\begin{array}{c}
	1 \\
	1
	\end{array}
	\right] + b_2 \cdot
	\left[
	\begin{array}{c}
	-1 \\
	1
	\end{array}
	\right].
	\end{equation} Os vetores da base $\mathcal{B}$ são representados na base canônica por
	\begin{equation}
	\left[
	\begin{array}{c}
	1 \\
	1
	\end{array}
	\right] =
	\left[
	\begin{array}{c}
	1 \\
	0
	\end{array}
	\right] +
	\left[
	\begin{array}{c}
	0 \\
	1
	\end{array}
	\right] = \vec{e}_1 + \vec{e}_2 \quad \text{e} \quad
	\left[
	\begin{array}{c}
	-1 \\
	1
	\end{array}
	\right] =
	\left[
	\begin{array}{c}
	-1 \\
	0
	\end{array}
	\right] +
	\left[
	\begin{array}{c}
	0 \\
	1
	\end{array}
	\right] = - \vec{e}_1 + \vec{e}_2.
	\end{equation} Logo,
	\begin{equation}
	\vec{v} = b_1 \left(  \vec{e}_1 + \vec{e}_2 \right) + b_2 \left(  - \vec{e}_1 + \vec{e}_2  \right) = (b_1 - b_2) \vec{e}_1 + (b_1 + b_2) \vec{e}_2,
	\end{equation} de modo que as componentes de $\vec{v}$ na base canônica são
	\begin{equation}
	\left\{
	\begin{array}{ll}
	x_1 = b_1 - b_2 \\
	x_2 = b_1 + b_2
	\end{array}
	\right..
	\end{equation} Em notação matricial:
	\begin{equation}
	\left[
	\begin{array}{c}
	x_1 \\
	x_2
	\end{array}
	\right] =
	\left[
	\begin{array}{cc}
	1 & -1 \\
	1 &  1
	\end{array}
	\right]
	\left[
	\begin{array}{c}
	b_1  \\
	b_2
	\end{array}
	\right].
	\end{equation}
\end{obs}

\subsection*{Exercícios resolvidos}

\construirExeresol

\subsection*{Exercícios}

\construirExer

\section{Exercícios finais}

\construirExer

%\end{document}
